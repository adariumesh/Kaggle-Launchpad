export interface NotebookOptions {
  includeEDA: boolean;
  includeBaseline: boolean;
  competitionType: 'classification' | 'regression' | 'nlp' | 'computer-vision' | 'other';
}

export interface KaggleNotebook {
  path: string;
  content: string;
  expectedScore?: string;
  description: string;
}

export class NotebookGenerator {
  private static detectCompetitionType(name: string): NotebookOptions['competitionType'] {
    const lowerName = name.toLowerCase();
    
    if (lowerName.includes('nlp') || lowerName.includes('sentiment') || lowerName.includes('text')) {
      return 'nlp';
    }
    if (lowerName.includes('image') || lowerName.includes('vision') || lowerName.includes('digit')) {
      return 'computer-vision';
    }
    if (lowerName.includes('price') || lowerName.includes('sales') || lowerName.includes('revenue')) {
      return 'regression';
    }
    return 'classification';
  }

  static async generateKaggleNotebook(
    competition: string,
    options: Omit<NotebookOptions, 'competitionType'>
  ): Promise<KaggleNotebook> {
    const competitionName = this.extractCompetitionName(competition);
    const competitionType = this.detectCompetitionType(competitionName);
    const fullOptions = { ...options, competitionType };

    const notebook = this.createSingleNotebook(competitionName, fullOptions);
    
    return {
      path: `${competitionName}-kaggle-notebook.ipynb`,
      content: notebook,
      expectedScore: this.getExpectedScore(competitionName, competitionType),
      description: `Complete Kaggle notebook for ${this.formatTitle(competitionName)} competition`
    };
  }

  private static extractCompetitionName(input: string): string {
    const urlMatch = input.match(/kaggle\.com\/competitions\/([^\/\?]+)/);
    return urlMatch ? urlMatch[1] : input.trim();
  }

  private static formatTitle(name: string): string {
    return name
      .split('-')
      .map(word => word.charAt(0).toUpperCase() + word.slice(1))
      .join(' ');
  }

  private static getExpectedScore(competition: string, type: NotebookOptions['competitionType']): string {
    const scoreMap: Record<string, string> = {
      'titanic': '0.77-0.82',
      'house-prices-advanced-regression-techniques': '0.12-0.15 RMSE',
      'digit-recognizer': '0.95-0.98',
      'nlp-getting-started': '0.80-0.85',
    };
    
    return scoreMap[competition] || (type === 'regression' ? '0.10-0.20 RMSE' : '0.75-0.85');
  }

  private static createSingleNotebook(competition: string, options: NotebookOptions): string {
    const title = this.formatTitle(competition);
    const isRegression = options.competitionType === 'regression';
    const isNLP = options.competitionType === 'nlp';
    const isCV = options.competitionType === 'computer-vision';

    const notebookContent = {
      cells: [
        // Header Cell
        {
          cell_type: "markdown",
          metadata: {},
          source: [
            `# üöÄ ${title} - Complete Kaggle Solution\n`,
            `**Generated by Kaggle Launchpad** | Expected Score: ${this.getExpectedScore(competition, options.competitionType)}\n\n`,
            `## üìã Competition Overview\n`,
            `- **Type**: ${options.competitionType.charAt(0).toUpperCase() + options.competitionType.slice(1)}\n`,
            `- **Goal**: ${this.getCompetitionGoal(options.competitionType)}\n`,
            `- **Evaluation**: ${this.getEvaluationMetric(options.competitionType)}\n\n`,
            `## üéØ Notebook Structure\n`,
            `1. **Setup & Data Loading** - Import libraries and load Kaggle data\n`,
            `2. **Exploratory Data Analysis** - Understand the data patterns\n`,
            `3. **Data Preprocessing** - Clean and prepare features\n`,
            `4. **Model Training** - Build and train baseline model\n`,
            `5. **Predictions & Submission** - Generate final submission\n\n`,
            `---`
          ]
        },

        // Setup Cell
        {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== KAGGLE ENVIRONMENT SETUP ======\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n\n",
            "# Kaggle-specific imports\n",
            "import os\n",
            "print(f\"Kaggle environment: {os.path.exists('/kaggle/input')}\")\n",
            "print(f\"GPU available: {os.path.exists('/opt/conda/bin/nvidia-smi')}\")\n\n",
            "# ML Libraries\n",
            this.getMLImports(options.competitionType),
            "\n# Visualization setup\n",
            "plt.style.use('seaborn-v0_8')\n",
            "sns.set_palette('husl')\n",
            "pd.set_option('display.max_columns', None)\n\n",
            "print(\"‚úÖ Setup complete!\")"
          ]
        },

        // Data Loading Cell
        {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== DATA LOADING ======\n",
            "# Kaggle input paths\n",
            `INPUT_DIR = '/kaggle/input/${competition}'\n`,
            "TRAIN_PATH = f'{INPUT_DIR}/train.csv'\n",
            "TEST_PATH = f'{INPUT_DIR}/test.csv'\n",
            "SAMPLE_SUB_PATH = f'{INPUT_DIR}/sample_submission.csv'\n\n",
            "# Load datasets\n",
            "print(\"üìÇ Loading data...\")\n",
            "train_df = pd.read_csv(TRAIN_PATH)\n",
            "test_df = pd.read_csv(TEST_PATH)\n",
            "sample_submission = pd.read_csv(SAMPLE_SUB_PATH)\n\n",
            "print(f\"Train shape: {train_df.shape}\")\n",
            "print(f\"Test shape: {test_df.shape}\")\n",
            "print(f\"Sample submission shape: {sample_submission.shape}\")\n\n",
            "# Display first few rows\n",
            "print(\"\\nüìä First 5 rows of training data:\")\n",
            "train_df.head()"
          ]
        },

        // EDA Cell (if enabled)
        ...(options.includeEDA ? [{
          cell_type: "markdown",
          metadata: {},
          source: ["## üîç Exploratory Data Analysis"]
        }, {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== QUICK EDA FUNCTIONS ======\n",
            "def quick_info(df, name='Dataset'):\n",
            "    print(f\"\\n=== {name.upper()} INFO ===\")\n",
            "    print(f\"Shape: {df.shape}\")\n",
            "    print(f\"\\nData types:\\n{df.dtypes.value_counts()}\")\n",
            "    print(f\"\\nMissing values:\\n{df.isnull().sum().sort_values(ascending=False).head(10)}\")\n",
            "    return df.describe()\n\n",
            "def plot_target_distribution(df, target_col):\n",
            "    plt.figure(figsize=(12, 4))\n",
            "    \n",
            "    plt.subplot(1, 2, 1)\n",
            "    df[target_col].hist(bins=30, edgecolor='black', alpha=0.7)\n",
            "    plt.title(f'{target_col} Distribution')\n",
            "    plt.xlabel(target_col)\n",
            "    plt.ylabel('Frequency')\n",
            "    \n",
            "    plt.subplot(1, 2, 2)\n",
            "    df[target_col].plot(kind='box')\n",
            "    plt.title(f'{target_col} Box Plot')\n",
            "    \n",
            "    plt.tight_layout()\n",
            "    plt.show()\n\n",
            "def plot_correlation_heatmap(df, figsize=(10, 8)):\n",
            "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
            "    if len(numeric_cols) > 1:\n",
            "        plt.figure(figsize=figsize)\n",
            "        correlation_matrix = df[numeric_cols].corr()\n",
            "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
            "        plt.title('Feature Correlation Matrix')\n",
            "        plt.tight_layout()\n",
            "        plt.show()\n",
            "        return correlation_matrix\n",
            "    return None"
          ]
        }, {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== DATA EXPLORATION ======\n",
            "# Basic info\n",
            "train_stats = quick_info(train_df, 'Training Data')\n",
            "test_stats = quick_info(test_df, 'Test Data')\n\n",
            "# Identify target column\n",
            this.getTargetIdentification(options.competitionType),
            "\n# Target analysis\n",
            "if target_col:\n",
            "    print(f\"\\nüéØ Target column: {target_col}\")\n",
            "    print(f\"Target statistics:\\n{train_df[target_col].describe()}\")\n",
            "    plot_target_distribution(train_df, target_col)\n\n",
            "# Correlation analysis\n",
            "correlation_matrix = plot_correlation_heatmap(train_df)\n",
            "if correlation_matrix is not None and target_col:\n",
            "    print(f\"\\nüîó Top features correlated with {target_col}:\")\n",
            "    target_corr = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
            "    print(target_corr.head(10))"
          ]
        }] : []),

        // Preprocessing Cell
        {
          cell_type: "markdown",
          metadata: {},
          source: ["## üõ†Ô∏è Data Preprocessing"]
        },
        {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== PREPROCESSING FUNCTIONS ======\n",
            "def preprocess_data(train_df, test_df, target_col=None):\n",
            "    \"\"\"Complete preprocessing pipeline optimized for Kaggle\"\"\"\n",
            "    print(\"üîß Starting preprocessing...\")\n",
            "    \n",
            "    # Combine for consistent preprocessing\n",
            "    train_len = len(train_df)\n",
            "    if target_col:\n",
            "        y = train_df[target_col].copy()\n",
            "        combined_df = pd.concat([train_df.drop(columns=[target_col]), test_df], ignore_index=True)\n",
            "    else:\n",
            "        y = None\n",
            "        combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
            "    \n",
            "    # Handle missing values\n",
            "    print(\"üìù Handling missing values...\")\n",
            "    numeric_cols = combined_df.select_dtypes(include=[np.number]).columns\n",
            "    categorical_cols = combined_df.select_dtypes(include=['object']).columns\n",
            "    \n",
            "    # Fill numeric missing values with median\n",
            "    for col in numeric_cols:\n",
            "        if combined_df[col].isnull().sum() > 0:\n",
            "            median_val = combined_df[col].median()\n",
            "            combined_df[col].fillna(median_val, inplace=True)\n",
            "    \n",
            "    # Fill categorical missing values with mode\n",
            "    for col in categorical_cols:\n",
            "        if combined_df[col].isnull().sum() > 0:\n",
            "            mode_val = combined_df[col].mode()[0] if len(combined_df[col].mode()) > 0 else 'Unknown'\n",
            "            combined_df[col].fillna(mode_val, inplace=True)\n",
            "    \n",
            "    # Encode categorical variables\n",
            "    print(\"üè∑Ô∏è Encoding categorical variables...\")\n",
            "    from sklearn.preprocessing import LabelEncoder\n",
            "    \n",
            "    label_encoders = {}\n",
            "    for col in categorical_cols:\n",
            "        le = LabelEncoder()\n",
            "        combined_df[col] = le.fit_transform(combined_df[col].astype(str))\n",
            "        label_encoders[col] = le\n",
            "    \n",
            this.getFeatureEngineering(options.competitionType),
            "    \n",
            "    # Split back to train and test\n",
            "    X_train = combined_df[:train_len].copy()\n",
            "    X_test = combined_df[train_len:].copy()\n",
            "    \n",
            "    print(f\"‚úÖ Preprocessing complete!\")\n",
            "    print(f\"Training features shape: {X_train.shape}\")\n",
            "    print(f\"Test features shape: {X_test.shape}\")\n",
            "    \n",
            "    return X_train, X_test, y, label_encoders\n\n",
            "# Apply preprocessing\n",
            "X_train, X_test, y, encoders = preprocess_data(train_df, test_df, target_col)"
          ]
        },

        // Model Training Cell (if enabled)
        ...(options.includeBaseline ? [{
          cell_type: "markdown",
          metadata: {},
          source: ["## ü§ñ Model Training & Validation"]
        }, {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== MODEL TRAINING ======\n",
            this.getModelCode(options.competitionType),
            "\n# Train-validation split\n",
            "from sklearn.model_selection import train_test_split\n",
            "X_tr, X_val, y_tr, y_val = train_test_split(\n",
            "    X_train, y, test_size=0.2, random_state=42",
            isRegression ? "" : ", stratify=y",
            "\n)\n\n",
            "print(f\"Training set: {X_tr.shape}\")\n",
            "print(f\"Validation set: {X_val.shape}\")\n\n",
            "# Train model\n",
            "print(\"üöÄ Training model...\")\n",
            "model.fit(X_tr, y_tr)\n",
            "print(\"‚úÖ Training complete!\")\n\n",
            "# Validation\n",
            "train_pred = model.predict(X_tr)\n",
            "val_pred = model.predict(X_val)\n\n",
            this.getEvaluationCode(options.competitionType),
            "\n# Feature importance (if available)\n",
            "if hasattr(model, 'feature_importances_'):\n",
            "    feature_importance = pd.DataFrame({\n",
            "        'feature': X_train.columns,\n",
            "        'importance': model.feature_importances_\n",
            "    }).sort_values('importance', ascending=False)\n",
            "    \n",
            "    plt.figure(figsize=(10, 6))\n",
            "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
            "    plt.title('Top 15 Feature Importances')\n",
            "    plt.tight_layout()\n",
            "    plt.show()\n",
            "    \n",
            "    print(\"\\nüîù Top 10 Important Features:\")\n",
            "    print(feature_importance.head(10))"
          ]
        }] : []),

        // Prediction & Submission Cell
        {
          cell_type: "markdown",
          metadata: {},
          source: ["## üì§ Final Predictions & Submission"]
        },
        {
          cell_type: "code",
          execution_count: null,
          metadata: {},
          outputs: [],
          source: [
            "# ====== GENERATE PREDICTIONS ======\n",
            "print(\"üîÆ Generating test predictions...\")\n",
            options.includeBaseline ? "test_predictions = model.predict(X_test)" : this.getSimplePredictions(options.competitionType),
            "\n\n# Create submission file\n",
            "submission = sample_submission.copy()\n",
            "submission.iloc[:, 1] = test_predictions  # Assuming second column is target\n\n",
            "# Save submission\n",
            "submission.to_csv('submission.csv', index=False)\n",
            "print(\"üíæ Submission saved as 'submission.csv'\")\n\n",
            "# Display submission info\n",
            "print(f\"\\nüìä Submission Statistics:\")\n",
            "print(f\"Shape: {submission.shape}\")\n",
            "print(f\"Predictions range: {test_predictions.min():.4f} to {test_predictions.max():.4f}\")\n",
            "print(f\"\\nFirst 10 predictions:\")\n",
            "print(submission.head(10))\n\n",
            "# Final validation\n",
            "print(f\"\\n‚úÖ Submission ready!\")\n",
            "print(f\"Expected score: {this.getExpectedScore(competition, options.competitionType)}\")\n",
            "print(f\"üí° Next steps: Submit to Kaggle and iterate!\")"
          ]
        },

        // Tips & Next Steps Cell
        {
          cell_type: "markdown",
          metadata: {},
          source: [
            "## üéØ Next Steps & Improvements\n\n",
            "### üöÄ Quick Wins:\n",
            "- **Feature Engineering**: Create interaction features, polynomial features\n",
            "- **Model Tuning**: Optimize hyperparameters with GridSearchCV\n",
            "- **Cross-Validation**: Implement robust CV strategy\n",
            "- **Ensemble**: Combine multiple models for better performance\n\n",
            "### üîß Advanced Techniques:\n",
            this.getAdvancedTips(options.competitionType),
            "\n### üìö Resources:\n",
            `- [Competition Discussion](https://www.kaggle.com/competitions/${competition}/discussion)\n`,
            `- [Competition Data](https://www.kaggle.com/competitions/${competition}/data)\n`,
            "- [Kaggle Learn](https://www.kaggle.com/learn)\n",
            "- [Feature Engineering Guide](https://www.kaggle.com/learn/feature-engineering)\n\n",
            "---\n",
            "**Generated by Kaggle Launchpad** üöÄ | Ready to submit and iterate!"
          ]
        }
      ],
      metadata: {
        kernelspec: {
          display_name: "Python 3",
          language: "python",
          name: "python3"
        },
        language_info: {
          codemirror_mode: { name: "ipython", version: 3 },
          file_extension: ".py",
          mimetype: "text/x-python",
          name: "python",
          nbconvert_exporter: "python",
          pygments_lexer: "ipython3",
          version: "3.10.0"
        }
      },
      nbformat: 4,
      nbformat_minor: 4
    };

    return JSON.stringify(notebookContent, null, 2);
  }

  private static getCompetitionGoal(type: NotebookOptions['competitionType']): string {
    const goals = {
      'classification': 'Predict categorical outcomes',
      'regression': 'Predict continuous numerical values',
      'nlp': 'Process and analyze text data',
      'computer-vision': 'Analyze and classify images',
      'other': 'Solve the specific competition challenge'
    };
    return goals[type];
  }

  private static getEvaluationMetric(type: NotebookOptions['competitionType']): string {
    const metrics = {
      'classification': 'Accuracy / F1-Score / AUC',
      'regression': 'RMSE / MAE / R¬≤',
      'nlp': 'Accuracy / F1-Score',
      'computer-vision': 'Accuracy / mAP',
      'other': 'Competition-specific metric'
    };
    return metrics[type];
  }

  private static getMLImports(type: NotebookOptions['competitionType']): string {
    const baseImports = `from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score`;

    const typeSpecific = {
      'classification': `
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier`,
      'regression': `
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor`,
      'nlp': `
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier`,
      'computer-vision': `
import torch
import torch.nn as nn
from torchvision import transforms
from sklearn.ensemble import RandomForestClassifier`,
      'other': `
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier`
    };

    return baseImports + typeSpecific[type];
  }

  private static getTargetIdentification(type: NotebookOptions['competitionType']): string {
    return `target_col = None
possible_targets = ['target', 'label', 'y', 'outcome', 'Survived', 'SalePrice', 'price']
for col in possible_targets:
    if col in train_df.columns:
        target_col = col
        break

if not target_col:
    # Try to identify target by position (usually last column)
    target_col = train_df.columns[-1]
    print(f"‚ö†Ô∏è Auto-detected target column: {target_col}")`;
  }

  private static getFeatureEngineering(type: NotebookOptions['competitionType']): string {
    const common = `
    # Basic feature engineering
    print("‚öôÔ∏è Creating new features...")
    
    # Add feature interaction (example)
    numeric_features = combined_df.select_dtypes(include=[np.number]).columns[:5]  # Top 5 numeric
    if len(numeric_features) >= 2:
        combined_df[f'{numeric_features[0]}_x_{numeric_features[1]}'] = combined_df[numeric_features[0]] * combined_df[numeric_features[1]]`;

    const typeSpecific = {
      'classification': common,
      'regression': common + `
    
    # Log transform for skewed features (regression specific)
    for col in numeric_features:
        if combined_df[col].skew() > 1:
            combined_df[f'{col}_log'] = np.log1p(combined_df[col])`,
      'nlp': `
    # Text-specific feature engineering would go here
    # For now, using basic preprocessing`,
      'computer-vision': `
    # Image-specific feature engineering would go here
    # For now, using basic preprocessing`,
      'other': common
    };

    return typeSpecific[type];
  }

  private static getModelCode(type: NotebookOptions['competitionType']): string {
    const models = {
      'classification': `# Initialize classifier
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    eval_metric='logloss'
)`,
      'regression': `# Initialize regressor  
model = XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)`,
      'nlp': `# Initialize NLP model
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42
)`,
      'computer-vision': `# Initialize CV model
model = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    random_state=42
)`,
      'other': `# Initialize model
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)`
    };

    return models[type];
  }

  private static getEvaluationCode(type: NotebookOptions['competitionType']): string {
    if (type === 'regression') {
      return `# Evaluation metrics
train_rmse = np.sqrt(mean_squared_error(y_tr, train_pred))
val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
val_mae = mean_absolute_error(y_val, val_pred)
val_r2 = r2_score(y_val, val_pred)

print(f"üìä Model Performance:")
print(f"Training RMSE: {train_rmse:.4f}")
print(f"Validation RMSE: {val_rmse:.4f}")
print(f"Validation MAE: {val_mae:.4f}")
print(f"Validation R¬≤: {val_r2:.4f}")

# Residual plot
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.scatter(val_pred, y_val, alpha=0.6)
plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Predicted vs Actual')

plt.subplot(1, 2, 2)
residuals = y_val - val_pred
plt.scatter(val_pred, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.tight_layout()
plt.show()`;
    } else {
      return `# Evaluation metrics
train_acc = accuracy_score(y_tr, train_pred)
val_acc = accuracy_score(y_val, val_pred)

print(f"üìä Model Performance:")
print(f"Training Accuracy: {train_acc:.4f}")
print(f"Validation Accuracy: {val_acc:.4f}")

print(f"\\nüìã Classification Report:")
print(classification_report(y_val, val_pred))

# Confusion Matrix
plt.figure(figsize=(6, 5))
cm = confusion_matrix(y_val, val_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()`;
    }
  }

  private static getSimplePredictions(type: NotebookOptions['competitionType']): string {
    if (type === 'regression') {
      return `# Simple baseline: use mean of target
mean_target = y.mean()
test_predictions = np.full(len(X_test), mean_target)
print(f"Using mean baseline: {mean_target:.4f}")`;
    } else {
      return `# Simple baseline: use mode of target  
mode_target = y.mode()[0]
test_predictions = np.full(len(X_test), mode_target)
print(f"Using mode baseline: {mode_target}")`;
    }
  }

  private static getAdvancedTips(type: NotebookOptions['competitionType']): string {
    const tips = {
      'classification': `- **Imbalanced Data**: Use SMOTE, class weights, or stratified sampling
- **Feature Selection**: Try SelectKBest, RFE, or L1 regularization
- **Advanced Models**: Try CatBoost, LightGBM, or Neural Networks
- **Stacking**: Combine predictions from multiple models`,
      'regression': `- **Target Engineering**: Try log transform, Box-Cox transformation
- **Outlier Handling**: Use IQR method or isolation forest
- **Advanced Models**: Try CatBoost, LightGBM, or Neural Networks  
- **Regularization**: Try Ridge, Lasso, or ElasticNet`,
      'nlp': `- **Text Preprocessing**: Stemming, lemmatization, stop word removal
- **Advanced Embeddings**: Word2Vec, GloVe, or transformer models
- **Feature Engineering**: N-grams, TF-IDF variations, sentiment scores
- **Deep Learning**: BERT, RoBERTa, or custom transformers`,
      'computer-vision': `- **Data Augmentation**: Rotation, scaling, flipping, color jittering
- **Transfer Learning**: Use pre-trained models (ResNet, EfficientNet)
- **Advanced Architectures**: Vision Transformers, EfficientNet
- **Ensemble**: Test Time Augmentation (TTA)`,
      'other': `- **Domain Research**: Study competition-specific techniques
- **Feature Engineering**: Create domain-specific features
- **Model Selection**: Try various algorithms for your problem type
- **Validation Strategy**: Use appropriate CV for your data`
    };

    return tips[type];
  }
}